\documentclass{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{polski}
\usepackage[T1]{fontenc}
 
\usepackage[margin=1.5in]{geometry} 

\usepackage{color} 
\usepackage{amsmath}
\usepackage{amsfonts}                                                                   
\usepackage{graphicx}                                                             
\usepackage{booktabs}
\usepackage{amsthm}
\usepackage{pdfpages}
\usepackage{wrapfig}
\usepackage{hyperref}
\usepackage{etoolbox}

\makeatletter
\newenvironment{definition}[1]{%
    \trivlist
    \item[\hskip\labelsep\textbf{Definition. #1.}]
    \ignorespaces
}{%
    \endtrivlist
}
\newenvironment{fact}[1]{%
    \trivlist
    \item[\hskip\labelsep\textbf{Fact. #1.}]
    \ignorespaces
}{%
    \endtrivlist
}
\newenvironment{theorem}[1]{%
    \trivlist
    \item[\hskip\labelsep\textbf{Theorem. #1.}]
    \ignorespaces
}{%
    \endtrivlist
}
\newenvironment{information}[1]{%
    \trivlist
    \item[\hskip\labelsep\textbf{Information. #1.}]
    \ignorespaces
}{%
    \endtrivlist
}
\newenvironment{identities}[1]{%
    \trivlist
    \item[\hskip\labelsep\textbf{Identities. #1.}]
    \ignorespaces
}{%
    \endtrivlist
}
\makeatother

\title{AiSD}  
\author{Rafał Włodarczyk}
\date{INA 4, 2025}

\begin{document}

\maketitle

\tableofcontents

\section{Lecture I - Losowe sortowanie}

Definiujemy problem:

\begin{enumerate}
    \item Input: $A=(a_1,\dots,a_n), |A|=n$
    \item Output: Permutacja tablicy wyjściowej $(a_1',a_2',\dots,a_n')$, takie że: $a_1'\leq a_2' \leq \dots \leq a_n'$.
\end{enumerate}

\subsection{Worst-case analysis}

\begin{align}
    T(n) = \max_{\text{wszystkie wejścia}}\{\text{\#operacji po wszystkich |n|-wejściach}\}
\end{align}

\subsection{Average-case analysis}

Zakładamy pewien rozkład prawdopodobieństwa na danych wejściowych. Z reguły myślimy o rozkładzie jednostajnym. Niech $T$ - zmienna losowa liczby operacji wykonanych przez badany algorytm.

\begin{align}
    \mathbf{E}(T) - \text{wartość oczekiwana T}
\end{align}

\noindent
Później możemy badać wariancję, oraz koncentrację.

\subsection{Analiza losowego sortowania}

Dla poprzedniego algorytmu zobaczmy, że: $n! \sim \sqrt{2\pi n} \left(\frac{n}{e}\right)^n$ $\left[\text{czyli } f(n)\sim g(n) \equiv \lim_{n\rightarrow \infty} \frac{f(n)}{g(n)} = 1 \right]$. To jest tragiczna złożoność.

\subsection{Insertion Sort $(A,n)$}

$(A,n) = ((a_1,a_2,\dots, a_n),n)$

\begin{verbatim}
for j = 2...n
{
    key = A[j]
    i=j-1
    while(i>0 && A[i]>key) {
        A[i+1] = A[i]
        i = i - 1
    }
    A[i+1] = key
}
\end{verbatim}

\noindent
Przykład: $A=(8, 2, 4, 9, 3, 6), n = 6$

\begin{itemize}
    \item $8_i, 2_j, 4, 9, 3, 6 \quad j=2, i=1, key = 2$ while
    \item $2, 8_j, 4, 9, 3, 6$
    \item $2, 8_i, 4_j, 9, 3, 6 \quad j=3, i=2, key = 4$ while
    \item $2, 4, 8, 9, 3, 6$
    \item $2, 4, 8_i, 9_j, 3, 6 \quad j=4, i=3, key = 9$ no while
    \item $2, 4, 8, 9_i, 3_j, 6 \quad j=5, i=4, key = 3$ while
    \item $2, 3, 4, 8, 9, 6$
    \item $2, 3, 4, 8, 9_i ,6_j \quad j=6, i=5, key = 6$ while
    \item $2, 3, 4, 6, 8, 9$
\end{itemize}

\begin{verbatim}
| <= x | > x | x | ... |
| <= x | x | > x | ... |
\end{verbatim}

\noindent
Porównujemy element ze wszystkim co jest przed nim - wszystko przed $j$-tym elementem będzie posortowane. Insertion sort nie swapuje par elementów w tablicy, a przenosi tam gdzie jest jego miejsce.

\subsubsection{Worst-case analysis - Insertion Sort $(A,n)$}

Odwrotnie posortowana tablica powoduje najwięcej przesunięć. Ponieważ ustaliśmy że liczba operacji w while zależy od $j$, wtedy:

\begin{align}
    T(n) &= \sum_{j=2}^n O(j-1) = \sum_{j=1}^{n-1} O(j) = O\left(\sum_{j=1}^{n-1} j\right) =\\
    &= O\left(\frac{1+n-1}{2}\cdot (n-1)\right) = O\left(\frac{(n-1)\cdot(n)}{2}\right) = O\left(\frac{n^2}{2}\right) = O(n^2)
\end{align}
c
\subsubsection{Average-case analysis - Insertion Sort $(A,n)$}

Policzmy dla uproszczenia, że na wejściu mamy $n$-elementowe permutacje, z których każda jest jednakowo prawdopodobna $p=\frac{1}{n!}$. Spróbujmy wyznaczyć $\mathbf{E}$, korzystając z inwersji permutacji. Wartość oczekiwana liczby inwersji w losowej permutacji wynosi:

\begin{align}
    \mathbf{E} \sim \frac{n^2}{4}
\end{align}

\noindent
Pominęliśmy stałe wynikające z innych operacji niż porównywanie. W average-case będziemy około połowę szybiciej niż w worst-case.\\

\noindent
\textit{Pseudokod bez przykładu jest słaby.}

\subsection{Przykład złożoności}

Patrzymy na wiodący czynnik.

\begin{align}
    13n^2 + 91n\log n + 4n + 13^{10} &= O(n^2)\\
    &= 13n^2 + O(n\log n)
\end{align}
\noindent
Chcielibyśmy gdzie to konieczne, zapisać \textit{lower order terms}.\\

\noindent
\textit{Pytanie o dzielenie liczb} - istnieją algorytmy, które ze względu na arytmetyczne właściwości liczb sprawiają, że mniejsze liczby mogą dzielić się dłużej niż większe. Podczas tego kursu nie omawiamy złożoności dla takich algorytmów.  

\section{Lecture II - Merge Sort}

\subsection{Merge sort $(A,1,n)$}

Niech złożoność T(n) - złożność algorytmu.

\newpage

\noindent
Funkcja merge sort
\begin{verbatim}
O(1)          | if |A[1...n]| == 1 return A[1...n]
              | else
T(floor(n/2)) |     B = MERGE_SORT(A,1,floor(n/2))
T(ceil(n/2))  |     C = MERGE_SORT(A,floor(n/2)+1, n)
O(n)          |     return MERGE(B,C)
\end{verbatim}

\noindent
Funkcja merge
\begin{verbatim}
MERGE(X[1...k], Y[1...l])
if k = 0 return Y[1...l]
if l = 0 return X[1...k]
if X[1] <= Y[1]
    return X[1] o MERGE(X[2...k], Y[1...l])
else   
    return Y[1] o MERGE(X[1...k], Y[2...l])
\end{verbatim}

\begin{verbatim}
MERGE(A,B)
2 1 ---> [1] + MERGE(A,B (bez 1))
7 9
13 10
19 11
20 14
  
2 9  ---> [1,2] + MERGE(A (bez 2),B)
7 10
13 11
19 14
20 .

... ---> [1,2,7,9,10,11,13,14]
19 .
20 .

... ---> [1,2,7,9,10,11,13,14,19,20]
\end{verbatim}

\begin{verbatim}
[10], [2], [5], [3], [7], [13], [1], [6]
[2, 10], [3,5], [7,13], [1,6]
[2,3,5,10], [1,6,7,13]
[1,2,3,5,6,7,10,13]
\end{verbatim}

\noindent
Złożoność obliczeniowa merge-a wynosi $O(k+l)$ - w najgorszym przypadku bierzemy najpierw z jednej strony, potem z drugiej i na zmianę.

\begin{align}
    T(n) &= T\left(\left\lfloor \frac{n}{2} \right\rfloor\right) + T\left(\left\lceil \frac{n}{2} \right\rceil\right) + O(n)\\
    T(n) &= 2\cdot T\left(\frac{n}{2}\right) + O(n)
\end{align}

\newpage

\noindent
Rozpiszmy tzw drzewo rekursji:

\begin{verbatim}
        cn                             | cn
       /  \                            |
  cn/2      cn/2                       | cn
  /   \     /   \                      |
cn/4 cn/4 cn/4 cn/4                    | cn
                                       |
      [...]                            | ...
                                       |
O(1) ... O(1) ... O(1) # liści mamy n  | cn
\end{verbatim}

\noindent
Musimy dodać wszystkie koszty, które pojawiły się w drzewie. Dodajmy piętra, a następnie zsumumjmy. 
Żeby znać wysokość drzewa interesuje nas dla jakiego $h$ zajdzie $\frac{n}{2^h} = 1$

\begin{align}
    \frac{n}{2^h} = 1 \implies 2^h = n \implies h = \log_2 n
\end{align}
Zatem złożność:
\begin{align}
    \sum_{i=1}^{\log n} cn = cn\log n \sim O(n\log n)
\end{align}

\end{document}
